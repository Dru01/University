% Preámbulo
\documentclass[letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}

\usepackage{enumitem}
\usepackage{titling}
\usepackage{setspace}
\usepackage{multicol}

% Símbolos
	\usepackage{amsmath}
	\usepackage{amssymb}
	\usepackage{amsthm}
	\usepackage{amsfonts}
	\usepackage{mathtools}
	\usepackage{bbm}
	\usepackage{minted}
	\usepackage[thinc]{esdiff}
	\allowdisplaybreaks

% Márgenes
	\usepackage
	[
		margin = 1.2in
	]
	{geometry}
	\onehalfspacing

% Imágenes
	\usepackage{float}
	\usepackage{graphicx}
	\graphicspath{{imagenes/}}
	\usepackage{subcaption}

% Ambientes
	\usepackage{amsthm}

	\theoremstyle{definition}
	\newtheorem{ejercicio}{Ejercicio}

	\newtheoremstyle{lemathm}{4pt}{0pt}{\itshape}{0pt}{\bfseries}{ --}{ }{\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}
	\theoremstyle{lemathm}
	\newtheorem{lema}{Lema}

	\newtheoremstyle{lemathm}{4pt}{0pt}{\itshape}{0pt}{\bfseries}{ --}{ }{\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}
	\theoremstyle{lemathm}
	\newtheorem{sol}{Solución}
	
	\newtheoremstyle{lemathm}{4pt}{0pt}{\itshape}{0pt}{\bfseries}{ --}{ }{\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}
	\theoremstyle{lemathm}
	\newtheorem{theo}{Teorema}

	\newtheoremstyle{lemademthm}{0pt}{10pt}{\itshape}{ }{\mdseries}{ --}{ }{\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}
	\theoremstyle{lemademthm}
	\newtheorem*{lemadem}{Demostración}

% Macros
	\newcommand{\sumi}[2]{\sum_{i=#1}^{#2}}
	\newcommand{\dint}[2]{\displaystyle\int_{#1}^{#2}}
	\newcommand{\inte}[2]{\int_{#1}^{#2}}
	\newcommand{\dlim}{\displaystyle\lim}
	\newcommand{\limxinf}{\lim_{x\to\infty}}
	\newcommand{\limninf}{\lim_{n\to\infty}}
	\newcommand{\dlimninf}{\displaystyle\lim_{n\to\infty}}
	\newcommand{\limh}{\lim_{h\to0}}
	\newcommand{\ddx}{\dfrac{d}{dx}}
	\newcommand{\txty}{\text{ y }}
	\newcommand{\txto}{\text{ o }}
	\newcommand{\Txty}{\quad\text{y}\quad}
	\newcommand{\Txto}{\quad\text{o}\quad}
	\newcommand{\si}{\text{si}\quad}

	\newcommand{\etiqueta}{\stepcounter{equation}\tag{\theequation}}
	\newcommand{\tq}{:}
	\renewcommand{\o}{\circ}
	\newcommand*{\QES}{\hfill\ensuremath{\blacksquare}}
	\newcommand*{\qes}{\hfill\ensuremath{\square}}
	\newcommand*{\QESHERE}{\tag*{$\blacksquare$}}
	\newcommand*{\qeshere}{\tag*{$\square$}}
	\newcommand*{\QED}{\hfill\ensuremath{\blacksquare}}
	\newcommand*{\QEDHERE}{\tag*{$\blacksquare$}}
	\newcommand*{\qel}{\hfill\ensuremath{\boxdot}}
	\newcommand*{\qelhere}{\tag*{$\boxdot$}}
	\renewcommand*{\qedhere}{\tag*{$\square$}}

	\newcommand{\suc}[1]{\left(#1_n\right)_{n\in\N}}
	\newcommand{\en}[2]{\binom{#1}{#2}}
	\newcommand{\upsum}[2]{U(#1,#2)}
	\newcommand{\lowsum}[2]{L(#1,#2)}
	\newcommand{\abs}[1]{\left| #1 \right| }
	\newcommand{\bars}[1]{\left \| #1 \right \| }
	\newcommand{\pars}[1]{\left( #1 \right) }
	\newcommand{\bracs}[1]{\left[ #1 \right] }
	\newcommand{\inprod}[1]{\left\langle #1 \right\rangle }
    \newcommand{\norm}[1]{\left\lVert#1\right\rVert}
	\newcommand{\floor}[1]{\left \lfloor #1 \right\rfloor }
	\newcommand{\ceil}[1]{\left \lceil #1 \right\rceil }
	\newcommand{\angles}[1]{\left \langle #1 \right\rangle }
	\newcommand{\set}[1]{\left \{ #1 \right\} }
	\newcommand{\norma}[2]{\left\| #1 \right\|_{#2} }


	\newcommand{\NN}{\mathbb{N}}
	\newcommand{\QQ}{\mathbb{Q}}
	\newcommand{\RR}{\mathbb{R}}
	\newcommand{\ZZ}{\mathbb{Z}}
	\newcommand{\PP}{\mathbb{P}}
    \newcommand{\EE}{\mathbb{E}}
	\newcommand{\1}{\mathbbm{1}}
	\newcommand{\eps}{\varepsilon}
	\newcommand{\ttF}{\mathtt{F}}
	\newcommand{\bfF}{\mathbf{F}}

	\newcommand{\To}{\longrightarrow}
	\newcommand{\mTo}{\longmapsto}
	\newcommand{\ssi}{\Longleftrightarrow}
	\newcommand{\sii}{\Leftrightarrow}
	\newcommand{\then}{\Rightarrow}

	\newcommand{\pTFC}{{\itshape 1er TFC\/}}
	\newcommand{\sTFC}{{\itshape 2do TFC\/}}


% Datos
    \title{Computo Paralelo \\ Tarea 4}
    \author{Rubén Pérez Palacios Lic. Computación Matemática\\Profesor: Dr. Francisco Javier Hernández López}
    \date{\today}

% DOCUMENTO
\begin{document}
	\maketitle

	\section*{Reportes}

	Se explica la solución de los ejercicios, así como la implementación en secuencial, paralelo en cpu y en gpu.

	Para todas las soluciones se uso la siguiente librería para el manejo de imagenes:

	Para la paralelización en cpu se uso la siguiente librería e instrucción:

	\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	#include <omp.h>
	omp_set_num_threads(8);//cantidad de hilos a paralelizar
	\end{minted}

	Para la paralelización en gpu se uso la siguiente librería e instrucción:

	\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	#include <cuda_runtime.h>
	#include <device_launch_parameters.h>
	cudaSetDevice(0);
	cudaMemcpy(/*...*/);//copiar memoria entre la gpu y algo mas
	cudaMalloc(/*...*/);//alocar memoria en la gpu 
	cudaDeviceSynchronize();//esperar a que la gpu termine de ejecutar kernels.
	cudaFree(/*...*/);//desalojar memoria en la gpu
	\end{minted}

	\newpage

	\subsection*{Ejercicio 1}

	\subsubsection*{Descripción}

	Dado un vector de números reales $V$ de tamaño $N$, programar lo siguiente

	\begin{enumerate}
		\item $S_1[i] = V[i] + V[i+1]$ para $i = 0,\cdots,N-2,$ con $S_1$ otro vector de tamaño $N-1$.
		\item $S_2[i] = \frac{V[i+1] + V[i-1]}{2}$ para $i = 1,\cdots,N-2,$ con $S_2$ otro vector de tamaño $N-2$.
	\end{enumerate}

	\subsubsection*{Solución}

	Se recorrio cada posición de $S_1,S_2$ para calcularlos con ciclos for
	
	\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	//S_1
	for (int i = 0; i < N - 1; i++)
        v_1[i] = v[i] + v[i + 1];
	//S_2
	for (int i = 1; i < N - 1; i++)
        v_1[i] = (v[i + 1] + v[i - 1])/2;
	\end{minted}

	\subsubsection*{Paralelización}

	\begin{enumerate}
		\item CPU:

		Se uso $omp\ parallel\ for$ con la directiva $default(shared)$ ya que las variables de iteración fueron declaradas localmente y todas puedan acceder a los vectores origen y al resultado.

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	//S_1
	#pragma omp parallel for default(shared)
    for (int i = 0; i < N - 1; i++)
        v_1[i] = v[i] + v[i + 1];
	//S_2
	#pragma omp parallel for default(shared)
    for (int i = 1; i < N - 1; i++)
        v_1[i] = (v[i + 1] + v[i - 1])/2;
		\end{minted}

		\item GPU:
		
		Para ello se hizo la alocación y copias de memoria para los vectores:

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	cudaMalloc((void**)&v_device, N * sizeof(long double));
	cudaMalloc((void**)&v_1_device, (N-1) * sizeof(long double));
	cudaMemcpy(v_device, v, N * sizeof(long double), cudaMemcpyHostToDevice);
		\end{minted}

		Después se uso una función kernel para resolver el problema, de tipo $\_\_global\_\_$, con número de bloques y tamaño de malla

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	int threads = 512, grid = divUp(N, threads);
		\end{minted}
		
		la cual es

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	//S_1
	__global__ void Solve(long double *v, long double *v_1, int N) {
		int idx = blockIdx.x * blockDim.x + threadIdx.x;
		if (idx < N) {
			v_1[idx] = v[idx] + v[idx + 1];
		}
	}
	//S_2
	__global__ void Solve(long double *v, long double *v_1, int N) {
		int idx = blockIdx.x * blockDim.x + threadIdx.x;
		if (idx < N) {
			v_1[idx] = (v[idx + 1] + v[idx - 1])/2;
		}
	}
		\end{minted}
	\end{enumerate}

	\newpage

	\subsection*{Ejercicio 2}

	\subsubsection*{Descripción}

	Dadas dos matrices $A$ y $B$ de tamaño $N\times M$ con valores enteros positivos, programar lo siguiente:

	\begin{enumerate}
		\item $C_1[i][j] = A[i][j] + B[N-1-i][M-1-j]$ para $i = 0,\cdots,N-1$ y $j = 0,\cdots,M-1$ con $C_1$ otra matriz de tamaño $N\times M$.
		\item $C_2[i][j] = (\alpha)*A[i][j] + (1-\alpha)*B[N-1-i][M-1-j]$ para $i = 0,\cdots,N-1$ y $j = 0,\cdots,M-1$, con $\alpha$ un número real constante entre $[0,1]$ y $C_1$ otra matriz de tamaño $N\times M$.
	\end{enumerate}

	\subsubsection*{Solución}

	Se recorrio cada posición de $C_1,C_2$ para calcularlos con 2 ciclos for anidados
	
	\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	//C_1
	for (int i = 0; i < N; i++)
        for (int j = 0; j < M; j++)
            C[i*M+j] = A[i*M+j] + B[(N - 1 - i)*M+(M - 1 - j)];
	//C_2
	for (int i = 0; i < N; i++)
        for (int j = 0; j < M; j++)
            C[i*M+j] = (alpha)*A[i*M+j] + (1 - alpha) * B[(N - 1 - i)*M+(M - 1 - j)];
	\end{minted}

	\subsubsection*{Paralelización}

	\begin{enumerate}
		\item CPU:

		Para la paralelización primero se uso $omp\ parallel\ for\ collapse(2)$, con las directivas $private(index, index1)$ porque cada iteración tiene su propio indice y $default(shared)$ ya que las variables de iteración fueron declaradas localmente y todas puedan accerder a las matrices por multiplicar y al resultado, así los primeros dos for anidados se paralelizaran.

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	//C_1
	#pragma omp parallel for collapse(2) default(shared)
    for (int i = 0; i < N; i++)
        for (int j = 0; j < M; j++)
            C[i*M+j] = A[i*M+j] + B[(N - 1 - i)*M+(M - 1 - j)];
	//C_2
	#pragma omp parallel for collapse(2) default(shared)
    for (int i = 0; i < N; i++)
        for (int j = 0; j < M; j++)
            C[i*M+j] = (alpha)*A[i*M+j] + (1 - alpha) * B[(N - 1 - i)*M+(M - 1 - j)];
		\end{minted}

		\item GPU:
		
		Para ello se hizo la alocación y copias de memoria para las matrices:

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	cudaMalloc((void**)&A_device, N * M * sizeof(double));
	cudaMalloc((void**)&B_device, N * M * sizeof(double));
	cudaMalloc((void**)&C_device, N * M * sizeof(double));
	cudaMemcpy(A_device, A, N * M * sizeof(double), cudaMemcpyHostToDevice);
	cudaMemcpy(B_device, B, N * M * sizeof(double), cudaMemcpyHostToDevice);
		\end{minted}

		Después se uso una función kernel para resolver el problema, de tipo $\_\_global\_\_$, con número de bloques y tamaño de malla

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	dim3 threads(16, 16, 1), grid(divUp(M, 16), divUp(N, 16), 1);
		\end{minted}
		
		la cual es

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	//C_1
	__global__ void Solve(double *A, double *B, double *C, int N, int M) {
		int idx = blockIdx.x * blockDim.x + threadIdx.x;
		int idy = blockIdx.y * blockDim.y + threadIdx.y;
		int index = (idy)*M + (idx);
		int index1 = (N - 1 - idy) * M + (M - 1 - idx);
		if (index < N*M) {
			C[index] = A[index] + B[index1];
		}
	}
	//C_2
	__global__ void Solve(double *A, double *B, double *C, double alpha, int N, int M) {
		int idx = blockIdx.x * blockDim.x + threadIdx.x;
		int idy = blockIdx.y * blockDim.y + threadIdx.y;
		int index = (idy)*M + (idx);
		int index1 = (N - 1 - idy) * M + (M - 1 - idx);
		if (index < N*M) {
			C[index] = (alpha)*A[index] + (1-alpha)*B[index1];
		}
	}
		\end{minted}
	\end{enumerate}

	\newpage

	\subsection*{Ejercicio 3}

	\subsubsection*{Descripción}

	Dada una matriz $A$ de tamaño $N\times K$ y una matriz $B$ de tamaño $K\times M$ con valores en punto flotante de 64 bits (double), programar la multiplicación de las matrices $A$ y $B$:

	\begin{enumerate}
		\item Usando OpenMP
		\item Usando CUDA con memoria global (GM)
		\item Usando CUDA con memoria compartida (SM)
	\end{enumerate}

	\subsubsection*{Solución}

	Se recorrio cada posición de $C$ para calcularla con 2 ciclos for anidados
	
	\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	for (int i = 0; i < N; i++)
    {
        for (int j = 0; j < M; j++)
        {
            C[i * M + j] = 0.0;
            for (int k = 0; k < K; k++)
                C[i * M + j] += A[i * K + k] * B[j * K + k];
        }
    }
	\end{minted}

	\subsubsection*{Paralelización}

	\begin{enumerate}
		\item CPU:

		Para la paralelización primero se uso $omp\ parallel\ for\ collapse(2)$, con las directivas $private(index, index1)$ porque cada iteración tiene su propio indice y $default(shared)$ ya que las variables de iteración fueron declaradas localmente y todas puedan accerder a las matrices por multiplicar y al resultado, así los primeros dos for anidados se paralelizaran.

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	#pragma omp parallel for collapse(2) default(shared)
    for (int i = 0; i < N; i++)
    {
        for (int j = 0; j < M; j++)
        {
            C[i * M + j] = 0.0;
            for (int k = 0; k < K; k++)
                C[i * M + j] += A[i * K + k] * B[j * K + k];
        }
    }
		\end{minted}

		\item GPU:
		
		Para ello se hizo la alocación y copias de memoria para las matrices:

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	cudaMalloc((void**)&A_device, N * K * sizeof(double));
	cudaMalloc((void**)&B_device, M * K * sizeof(double));
	cudaMalloc((void**)&C_device, N * M * sizeof(double));
	cudaMemcpy(A_device, A, N * K * sizeof(double), cudaMemcpyHostToDevice);
	cudaMemcpy(B_device, B, M * K * sizeof(double), cudaMemcpyHostToDevice);
		\end{minted}

		Después se uso una función kernel para resolver el problema, de tipo $\_\_global\_\_$, con número de bloques y tamaño de malla

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	dim3 threads(16, 16, 1), grid(divUp(M, 16), divUp(N, 16), 1);
		\end{minted}
		
		la cual es

		\begin{minted}[bgcolor=gray!10!,breaklines]{cpp}
	__global__ void mat_prod(double *A, double *B, double *C, int N, int K, int M)
	{
		int idx = blockIdx.x * blockDim.x + threadIdx.x;
		int idy = blockIdx.y * blockDim.y + threadIdx.y;
		int index = (idy)*M + (idx);
		C[index] = 0.0;
		for (int k = 0; k < K; k++)
			C[index] += A[idy * K + k] * B[idx * K + k];
	}
		\end{minted}
	\end{enumerate}

\end{document}

