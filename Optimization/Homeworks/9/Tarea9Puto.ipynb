{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de Optimización (DEMAT)\n",
    "## Tarea 9\n",
    "\n",
    "| Descripción:                         | Fechas               |\n",
    "|--------------------------------------|----------------------|\n",
    "| Fecha de publicación del documento:  | **Abril 28, 2022**   |\n",
    "| Fecha límite de entrega de la tarea: | **Mayo   8, 2022**   |\n",
    "\n",
    "\n",
    "### Indicaciones\n",
    "\n",
    "- Envie el notebook que contenga los códigos y las pruebas realizadas de cada ejercicio.\n",
    "- Si se requiren algunos scripts adicionales para poder reproducir las pruebas,\n",
    "  agreguelos en un ZIP junto con el notebook.\n",
    "- Genere un PDF del notebook y envielo por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 0 (0 puntos)\n",
    "\n",
    "- Empezar a buscar un tema para el proyecto final del curso.\n",
    "- En esta tarea no hay que poner la descripción del proyecto.\n",
    "  Sólo buscar el tema y tenerlo listo para su entrega en la\n",
    "  siguiente tarea.\n",
    "- La fecha límite para mandar la descripción del proyecto\n",
    "  se tiene que mandar es el domingo 17 de mayo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1. (2 puntos)\n",
    "\n",
    "Programar las siguientes funciones y sus gradientes, de modo que dependan de la dimensión $n$ de la variable $\\mathbf{x}$:\n",
    "\n",
    "\n",
    "- Función \"Tridiagonal 1\" generalizada\n",
    "\n",
    "$$  f(x) = \\sum_{i=1}^{n-1} (x_i + x_{i+1} - 3)^2 + (x_i - x_{i+1} + 1)^4  $$\n",
    "\n",
    "\n",
    "- Función generalizada de Rosenbrock\n",
    "\n",
    "$$  f(x) = \\sum_{i=1}^{n-1} 100(x_{i+1} - x_i^2)^2 + (1 - x_{i} )^2  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#  Implementación de la función Tridiagonal y su gradiente\n",
    "def tridiagonal(x):\n",
    "    x1 = x[:-1]\n",
    "    x2 = x[1:]\n",
    "\n",
    "    x3 = (x1 + x2 - 3)**2 + (x1 - x2 + 1)**4\n",
    "    return np.sum(x3)\n",
    "\n",
    "def g_tridiagonal(x):\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    x1 = x[:-1]\n",
    "    x2 = x[1:]\n",
    "    \n",
    "    d1 = 2 * (x1 + x2 - 3) + 4 * (x1 - x2 + 1)**3\n",
    "    d2 = 2 * (x1 + x2 - 3) - 4 * (x1 - x2 + 1)**3\n",
    "    \n",
    "    d = np.zeros((n,))\n",
    "    d[0] = d1[0]\n",
    "    d[1:-1] = d1[1:] + d2[:-1]\n",
    "    d[-1] = d2[-1]\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Implementación de la función generalizada de Rosenbrock y su gradiente\n",
    "\n",
    "def rosenbrock(x):\n",
    "    x1 = x[:-1]\n",
    "    x2 = x[1:]\n",
    "\n",
    "    x3 = 100 * (x2 - x1**2)**2 + (1-x1)**2\n",
    "    return np.sum(x3)\n",
    "    \n",
    "def g_rosenbrock(x):\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    x1 = x[:-1]\n",
    "    x2 = x[1:]\n",
    "    \n",
    "    d1 = -400 * (x2 - x1**2) * x1 - 2 * (1 - x1)\n",
    "    d2 = 200 * (x2 - x1**2)\n",
    "    \n",
    "    d = np.zeros((n,))\n",
    "    d[0] = d1[0]\n",
    "    d[1:-1] = d1[1:] + d2[:-1]\n",
    "    d[-1] = d2[-1]\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 (8 puntos)\n",
    "\n",
    "Programar y probar el método BFGS modificado.\n",
    "\n",
    "\n",
    "1. Programar el algoritmo descrito en la diapositiva 16 de la clase 23.\n",
    "   Agregue una variable $res$ que indique si el algoritmo terminó\n",
    "   porque se cumplió que la magnitud del gradiente es menor que la toleracia\n",
    "   dada.\n",
    "2. Probar el algoritmo con las funciones del Ejercicio 1\n",
    "   con la matriz $H_0$ como la matriz identidad y el \n",
    "   punto inicial $x_0$ como:\n",
    "\n",
    "- La función generalizada de Rosenbrock: \n",
    "\n",
    "$$ x_0 = (-1.2, 1, -1.2, 1, ..., -1.2, 1) \\in \\mathbb{R}^n$$\n",
    "\n",
    "- La función Tridiagonal 1 generalizada: \n",
    "\n",
    "$$ x_0 = (2,2, ..., 2) \\in \\mathbb{R}^n $$\n",
    "  \n",
    "  Pruebe el algoritmo con la dimensión $n=2, 10 , 100$.\n",
    "\n",
    "3. Fije el número de iteraciones máximas a $N=50000$, \n",
    "   y la tolerancia $\\tau = \\epsilon_m^{1/3}$, donde $\\epsilon_m$\n",
    "   es el épsilon máquina, para terminar las iteraciones \n",
    "   si la magnitud del gradiente es menor que $\\tau$.\n",
    "   En cada caso, imprima los siguiente datos:\n",
    "   \n",
    "- $n$,\n",
    "- $f(x_0)$, \n",
    "- Usando la variable $res$, imprima un mensaje que indique si\n",
    "  el algoritmo convergió,\n",
    "- el  número $k$ de iteraciones realizadas,\n",
    "- $f(x_k)$,\n",
    "- la norma del vector $\\nabla f_k$, y\n",
    "- las primeras y últimas 4 entradas del punto $x_k$ que devuelve el algoritmo.\n",
    "  \n",
    "\n",
    "### Solución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(f, xk, pk, p, beta):\n",
    "    alpha = 1\n",
    "    fk = f(xk)\n",
    "    while True:\n",
    "        if f(xk + alpha * pk) <= fk - beta*alpha*(pk.T @ pk):\n",
    "            return alpha\n",
    "        alpha = p * alpha\n",
    "\n",
    "def BFGS(fun, grad, x0, H0, maxN, tol):\n",
    "    res = 0\n",
    "    n = x0.shape[0]\n",
    "    Hk = H0\n",
    "    \n",
    "    x_new = x0\n",
    "    g_new = grad(x_new)\n",
    "    \n",
    "    for k in range(maxN):\n",
    "        xk = x_new\n",
    "        gk = g_new\n",
    "        #print(xk, gk)\n",
    "        \n",
    "        if np.linalg.norm(gk) <= tol:\n",
    "            res = 1\n",
    "            break\n",
    "        \n",
    "        pk = -Hk @ gk\n",
    "        \n",
    "        if pk.T @ gk > 0:\n",
    "            lamb1 = 10**(-5) + (pk.T @ gk) / (gk.T @ gk)\n",
    "            Hk = Hk + lamb1 * np.eye(n)\n",
    "            pk = pk - lamb1 * gk\n",
    "        \n",
    "        alpha = backtracking(fun, xk, pk, 0.8, 0.0001)\n",
    "        x_new = xk + alpha * pk\n",
    "        g_new = grad(x_new)\n",
    "\n",
    "        sk = x_new - xk\n",
    "        yk = g_new - gk\n",
    "\n",
    "        lamb2 = 10**(-5) - (yk.T @ sk) / (sk.T @ sk)\n",
    "        if yk.T @ sk <= 0:\n",
    "            Hk = Hk + lamb2 * np.eye(n)\n",
    "        else:\n",
    "            rho = 1 / (yk.T @ sk)\n",
    "            Hk = (np.eye(n) - rho * sk @ yk.T) @ Hk @ (np.eye(n) - rho * yk @ sk.T) + rho * sk @ sk.T\n",
    "        \n",
    "        if np.abs(g_new.T @ gk) > 0.2 * np.linalg.norm(g_new)**2:\n",
    "            # Reinicio\n",
    "            Hk = np.eye(n)\n",
    "                \n",
    "    return xk, gk, k, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BFGS | Tridiagonal\n",
      "n = 2\n",
      "f(x0) = 2.0\n",
      "xk = ( 0.9968641547054268 2.003137883035577 )\n",
      "||gk|| = 5.930456824986014e-06\n",
      "f(xk) = 1.5533357873849146e-09\n",
      "k = 3163\n",
      "El algoritmo convergio\n",
      "\n",
      "Test BFGS | Tridiagonal\n",
      "n = 10\n",
      "f(x0) = 18.0\n",
      "xk = ( 1.0246464559571948 1.3436102047625293 1.4389090298938394 1.476453221824012 ... 1.523546778175988 1.5610909701061606 1.6563897952374707 1.9753535440428052 )\n",
      "||gk|| = 5.7363218184731905e-06\n",
      "f(xk) = 7.211216703291889\n",
      "k = 258\n",
      "El algoritmo convergio\n",
      "\n",
      "Test BFGS | Tridiagonal\n",
      "n = 100\n",
      "f(x0) = 198.0\n",
      "xk = ( 1.0244815803139797 1.3432606516996888 1.4381179955589474 1.4745905383926357 ... 1.5254094541662702 1.5618819963385921 1.65673933312725 1.9755183835721504 )\n",
      "||gk|| = 4.4551032117350855e-06\n",
      "f(xk) = 97.21030748599117\n",
      "k = 62\n",
      "El algoritmo convergio\n",
      "\n",
      "\n",
      "Test BFGS | Rosenbrock\n",
      "n = 2\n",
      "f(x0) = 24.199999999999996\n",
      "xk = ( 1.0000029421689873 1.0000058839580541 )\n",
      "||gk|| = 6.040269183391008e-06\n",
      "f(xk) = 8.656373449210375e-12\n",
      "k = 16816\n",
      "El algoritmo convergio\n",
      "\n",
      "Test BFGS | Rosenbrock\n",
      "n = 10\n",
      "f(x0) = 2057.0\n",
      "xk = ( 0.9999999929684152 0.9999999845984702 0.9999999716214408 0.9999999396661543 ... 0.9999995254722672 0.9999990451347599 0.9999980879936743 0.9999961651179716 )\n",
      "||gk|| = 6.051541949616569e-06\n",
      "f(xk) = 4.8903966157907195e-12\n",
      "k = 21547\n",
      "El algoritmo convergio\n",
      "\n",
      "Test BFGS | Rosenbrock\n",
      "n = 100\n",
      "f(x0) = 24926.000000000004\n",
      "xk = ( 0.9999999999908615 1.0000000000228373 0.9999999999634867 1.0000000000501534 ... 0.9999994916034715 0.9999989807886005 0.9999979563998628 0.999995902627068 )\n",
      "||gk|| = 6.038126168895802e-06\n",
      "f(xk) = 5.581546974537853e-12\n",
      "k = 35468\n",
      "El algoritmo convergio\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pruebas realizadas \n",
    "\n",
    "def short(x):\n",
    "    if x.shape[0] <= 8:\n",
    "        print('(', *x, ')')\n",
    "        return\n",
    "    y = np.ones((8,))\n",
    "    y[:4] = x[:4]\n",
    "    y[4:] = x[-4:]\n",
    "    print('(', *x[:4], '...', *x[-4:], ')' )\n",
    "\n",
    "def test_BFGS(n, fun, grad, x0, maxN, tol, mess):\n",
    "    print(f\"Test BFGS | {mess}\")\n",
    "    print(f'n = {n}')\n",
    "    print(f'f(x0) = {fun(x0)}')\n",
    "    \n",
    "    xk, gk, k, res = BFGS(fun, grad, x0, np.eye(n), maxN, tol)\n",
    "    \n",
    "    print('xk = ', end='')\n",
    "    short(xk)\n",
    "    print(f'||gk|| = {np.linalg.norm(gk)}')\n",
    "    print(f'f(xk) = {fun(xk)}')\n",
    "    print(f'k = {k}')\n",
    "    if res == 1:\n",
    "        print(f'El algoritmo convergio')\n",
    "    else:\n",
    "        print('El algoritmo no convergio')\n",
    "    print()\n",
    "\n",
    "\n",
    "EPS_M = np.finfo(float).eps\n",
    "MAX_N = 50000\n",
    "TOL = EPS_M ** (1/3)\n",
    "\n",
    "NN = (2, 10, 100)\n",
    "\n",
    "for n in NN:\n",
    "    x0 = np.ones((n,))\n",
    "    x0 = x0 * 2\n",
    "    test_BFGS(n, tridiagonal, g_tridiagonal, x0, MAX_N, TOL, 'Tridiagonal')\n",
    "print()\n",
    "\n",
    "for n in NN:\n",
    "    x0 = np.ones((n,))\n",
    "    x0[::2] = -1.2\n",
    "    test_BFGS(n, rosenbrock, g_rosenbrock, x0, MAX_N, TOL, 'Rosenbrock')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
