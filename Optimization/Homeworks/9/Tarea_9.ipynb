{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de Optimización (DEMAT)\n",
    "## Tarea 9\n",
    "\n",
    "| Descripción:                         | Fechas               |\n",
    "|--------------------------------------|----------------------|\n",
    "| Fecha de publicación del documento:  | **Abril 28, 2022**   |\n",
    "| Fecha límite de entrega de la tarea: | **Mayo   8, 2022**   |\n",
    "\n",
    "\n",
    "### Indicaciones\n",
    "\n",
    "- Envie el notebook que contenga los códigos y las pruebas realizadas de cada ejercicio.\n",
    "- Si se requiren algunos scripts adicionales para poder reproducir las pruebas,\n",
    "  agreguelos en un ZIP junto con el notebook.\n",
    "- Genere un PDF del notebook y envielo por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import line_search\n",
    "\n",
    "EPS = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1. (2 puntos)\n",
    "\n",
    "Programar las siguientes funciones y sus gradientes, de modo que dependan de la dimensión $n$ de la variable $\\mathbf{x}$:\n",
    "\n",
    "\n",
    "- Función \"Tridiagonal 1\" generalizada\n",
    "\n",
    "$$  f(x) = \\sum_{i=1}^{n-1} (x_i + x_{i+1} - 3)^2 + (x_i - x_{i+1} + 1)^4  $$\n",
    "\n",
    "\n",
    "- Función generalizada de Rosenbrock\n",
    "\n",
    "$$  f(x) = \\sum_{i=1}^{n-1} 100(x_{i+1} - x_i^2)^2 + (1 - x_{i} )^2  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de la funciones y sus gradientes\n",
    "import numpy as np\n",
    "\n",
    "def tridiagonal_one(x):\n",
    "    t = np.copy(x).squeeze()[:-1]\n",
    "    s = np.copy(x).squeeze()[1:]\n",
    "    return sum((t+s-3)**2 + (t-s)**4)\n",
    "\n",
    "def tridiagonal_one_gradient(x):\n",
    "    t = np.copy(x).squeeze()[:-1]\n",
    "    s = np.copy(x).squeeze()[1:]\n",
    "    t = np.concatenate((2*((t+s-3) - 2*(t-s+1)**3),np.array([0])))\n",
    "    s = np.concatenate((np.array([0]),2*((t+s-3) - 2*(t-s+1)**3)))\n",
    "    return np.concatenate((2*((t+s-3) - 2*(t-s+1)**3),np.array([0]))) + np.concatenate((np.array([0]),2*((t+s-3) - 2*(t-s+1)**3)))\n",
    "\n",
    "def rosenbrock(x):\n",
    "    t = np.copy(x).squeeze()[:-1]\n",
    "    s = np.copy(x).squeeze()[1:]\n",
    "    return sum(100*(t-s**2)**2 + (1-t)**2)\n",
    "\n",
    "def rosenbrock_gradient(x):\n",
    "    t = np.copy(x).squeeze()[:-1]\n",
    "    s = np.copy(x).squeeze()[1:]\n",
    "    t = np.concatenate((2*((t+s-3) - 2*(t-s+1)**3),np.array([0])))\n",
    "    s = np.concatenate((np.array([0]),2*((t+s-3) - 2*(t-s+1)**3)))\n",
    "    return np.concatenate((2*((t+s-3) - 2*(t-s+1)**3),np.array([0]))) + np.concatenate((np.array([0]),2*((t+s-3) - 2*(t-s+1)**3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 (8 puntos)\n",
    "\n",
    "Programar y probar el método BFGS modificado.\n",
    "\n",
    "\n",
    "1. Programar el algoritmo descrito en la diapositiva 16 de la clase 23.\n",
    "   Agregue una variable $res$ que indique si el algoritmo terminó\n",
    "   porque se cumplió que la magnitud del gradiente es menor que la toleracia\n",
    "   dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModificacionBFGS(x0, tol, funcion, grad, H0, MAX_IT):\n",
    "    k = 0\n",
    "    xk = np.copy(x0)\n",
    "    Hk = np.copy(H0)\n",
    "    N, N = Hk.shape\n",
    "    I = np.identity(N)\n",
    "    res = 0\n",
    "    \n",
    "    alpha_f = lambda x, p : line_search(funcion, grad, x, p)\n",
    "\n",
    "    while k < MAX_IT:\n",
    "        gk = grad(xk)\n",
    "\n",
    "        if np.linalg.norm(gk) < tol:\n",
    "            res = 1\n",
    "            break\n",
    "        \n",
    "        pk = -np.matmul(gk.T,Hk.T)\n",
    "\n",
    "        if np.matmul(gk.T, pk) > 0:\n",
    "            lambda_1 = 10**(-5) + (np.matmul(gk.T, pk) / np.matmul(gk.T, gk))[0][0]\n",
    "            Hk = Hk + lambda_1 * I\n",
    "            pk = pk - lambda_1 * gk\n",
    "        \n",
    "        alpha_k = alpha_f(xk, pk)[0]\n",
    "        xk_1 = xk + alpha_k * pk\n",
    "        gk_1 = grad(xk_1)\n",
    "        sk = xk_1 - xk\n",
    "        yk = gk_1 - gk\n",
    "\n",
    "        if np.matmul(yk.T, sk) < 0:\n",
    "            lambda_2 = 10**(-5) - (np.matmul(yk.T, sk) / np.matmul(sk.T, sk))[0][0]\n",
    "            Hk_1 = Hk + lambda_2 * I\n",
    "        else :\n",
    "            rhok = 1 / (np.matmul(yk.T, sk)[0][0])\n",
    "            Hk_1 = ( \n",
    "                (I - rhok * np.matmul(sk, yk.T)) @ \n",
    "                Hk @ \n",
    "                (I - rhok * np.matmul(yk, sk.T)) +\n",
    "                rhok* np.matmul(sk, sk.T) \n",
    "            )\n",
    "        \n",
    "        k = k + 1\n",
    "        xk = xk_1\n",
    "        Hk = Hk_1\n",
    "        gk = gk_1\n",
    "\n",
    "    return res, k, xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Fije el número de iteraciones máximas a $N=50000$, \n",
    "   y la tolerancia $\\tau = \\epsilon_m^{1/3}$, donde $\\epsilon_m$\n",
    "   es el épsilon máquina, para terminar las iteraciones \n",
    "   si la magnitud del gradiente es menor que $\\tau$.\n",
    "   En cada caso, imprima los siguiente datos:\n",
    "   \n",
    "- $n$,\n",
    "- $f(x_0)$, \n",
    "- Usando la variable $res$, imprima un mensaje que indique si\n",
    "  el algoritmo convergió,\n",
    "- el  número $k$ de iteraciones realizadas,\n",
    "- $f(x_k)$,\n",
    "- la norma del vector $\\nabla f_k$, y\n",
    "- las primeras y últimas 4 entradas del punto $x_k$ que devuelve el algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probarBFGSModificado(funcion, grad, x0, H0):\n",
    "    N = x0.shape[0]\n",
    "    res, k, xk = ModificacionBFGS(x0, EPS**(1/3), funcion, grad, H0, 50000)\n",
    "    mensaje = \"El algoritmo convergio\" if res == 1 else \"El algoritmo no convergio\"\n",
    "    fx0 = funcion(x0)\n",
    "    norma = np.linalg.norm(grad(xk))\n",
    "\n",
    "    print(f\"\"\"\n",
    "    N = {N}\n",
    "    fx0 = {fx0}\n",
    "    {mensaje}\n",
    "    k = {k}\n",
    "    Norma = {norma}\n",
    "    {xk[0,:4]} ... {xk[0, -4:]}\n",
    "    \"\"\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Probar el algoritmo con las funciones del Ejercicio 1\n",
    "   con la matriz $H_0$ como la matriz identidad y el \n",
    "   punto inicial $x_0$ como:\n",
    "\n",
    "- La función generalizada de Rosenbrock: \n",
    "\n",
    "$$ x_0 = (-1.2, 1, -1.2, 1, ..., -1.2, 1) \\in \\mathbb{R}^n$$\n",
    "\n",
    "- La función Tridiagonal 1 generalizada: \n",
    "\n",
    "$$ x_0 = (2,2, ..., 2) \\in \\mathbb{R}^n $$\n",
    "  \n",
    "  Pruebe el algoritmo con la dimensión $n=2, 10 , 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    N = 2\n",
      "    fx0 = 24.199999999999996\n",
      "    El algoritmo convergio\n",
      "    k = 34\n",
      "    Norma = 1.0506606472597589e-07\n",
      "    [1.00000001] ... [1.00000001]\n",
      "    \n",
      "\n",
      "    N = 10\n",
      "    fx0 = 2057.0\n",
      "    El algoritmo convergio\n",
      "    k = 79\n",
      "    Norma = 3.8065248406907815e-07\n",
      "    [1.] ... [1.]\n",
      "    \n",
      "\n",
      "    N = 100\n",
      "    fx0 = 24926.000000000022\n",
      "    El algoritmo convergio\n",
      "    k = 481\n",
      "    Norma = 4.451490414011326e-06\n",
      "    [1.] ... [1.]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for n in [2, 10, 100]:\n",
    "    I = np.identity(n)\n",
    "    x0 = np.array([ [-1.2, 1] * (n // 2) ]).T\n",
    "    probarBFGSModificado(rosenbrock, rosenbrock_grad, x0, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    N = 2\n",
      "    fx0 = 12.313600000000003\n",
      "    El algoritmo convergio\n",
      "    k = 16\n",
      "    Norma = 5.696183696343298e-06\n",
      "    [1.00500746] ... [1.00500746]\n",
      "    \n",
      "\n",
      "    N = 10\n",
      "    fx0 = 521.9584000000001\n",
      "    El algoritmo convergio\n",
      "    k = 32\n",
      "    Norma = 3.0291171643043342e-06\n",
      "    [1.02464635] ... [1.02464635]\n",
      "    \n",
      "\n",
      "    N = 100\n",
      "    fx0 = 6255.4624000000085\n",
      "    El algoritmo convergio\n",
      "    k = 125\n",
      "    Norma = 1.118182174353982e-06\n",
      "    [1.02448172] ... [1.02448172]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for n in [2, 10, 20]:\n",
    "    I = np.identity(n)\n",
    "    x0 = np.array([ [-1.2, 1] * (n // 2) ]).T\n",
    "    probarBFGSModificado(tridiagonal, tridiagonal_grad, x0, I)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cde0f83046ffad4b59996d01fbf0562c0aac47b8af8eae0c030af8453f5ead98"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
